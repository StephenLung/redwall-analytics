---
title: Exploring Big MT Cars with Python datatable and plotnine
author: David Lucey
date: '2020-05-07'
slug: exploring-big-mt-cars-with-python-datatable-and-plotnine
categories: ["R", "Code-Oriented"]
tags: ["data.table", "datatable", "plotnine"]
output:
  html_document:
    code_folding: 'hide'
---


```{r 'setup', message=FALSE, warning=FALSE, include=TRUE}
# R Libraries
library("reticulate")
library("skimr")

knitr::opts_chunk$set(
  fig.width = 15,
  fig.height = 8,
  out.width = '100%')

```


```{r 'reticulate', echo=TRUE, message=FALSE, warning=FALSE}
# Choose Python 3.7 miniconda
reticulate::use_condaenv(
  condaenv = "datatable",
  conda = "/Users/davidlucey/opt/anaconda3/bin/conda",
  required = TRUE
  )

```


```{r 'install-conda', message=FALSE, warning=FALSE, eval = FALSE}
# Install Python packages
lapply(c("plotnine", "datatable"), function(package) {
       conda_install("datatable", package, pip = TRUE)
})

```


```{python 'python-setup'}
# Python libraries
import datatable as dt
from datatable import *
import numpy as np
import re
import pprint

```

# Introduction

As mentioned in our last series [Parsing Mass Municipal PDF CAFRs with Tabulizer, pdftools and AWS Textract - Part 1](https://redwallanalytics.com/2020/03/31/parsing-mass-municipal-pdf-cafrs-with-tabulizer-pdftools-and-aws-textract-part-1/) and [A Walk Though of Accessing Financial Statements with XBRL in R - Part 1](https://redwallanalytics.com/2020/02/18/a-walk-though-of-accessing-financial-statements-with-xbrl-in-r-part-1/), this is a year of clean-up. Redwall Analytics is going through this year, and solving problems previously encountered, but beyond our capabilities at the time. It is doing this by combining R and Python tools via `reticulate`, as we did with our series on `pdftools`, `tabulizer` and AWS `Textract`. Although we have worked with some Python, we have been hoping to leveraging the familiar syntax of two of our favorite R libraries, `data.table` and `ggplot2` to bridge our way into the language. 

Python's `datatable` was launched by `h2o` two years ago, and feels similar to the R version, with a few syntax differences and also some important pieces still to be added (as we will discuss). We could only find a handful of posts showing how to use `datatable`, and most of the examples we found were probably not written by regular users of R `data.table`. We use `data.table` every day and love the speed and concise syntax, so this walk-through analysis of the EPA's Big MT cars data set will be from that perspective. As for `plotnine`, it feels more seamless with `ggplot2` with a few problems formatting plots in Rmarkdown. 


# EPA's Big MT Dataset

To make it a little interesting, we will use the [Tidy Tuesday Big MT Cars]("https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-10-15") with 36 years of 42,230 new US car models. The data dictionary with 83 variables describing each annual new car model is found [here](https://www.fueleconomy.gov/feg/ws/index.shtml#fuelType1). Everyone loves cars and remembering historical models, and we have naturally been curious about this data set. After closer analysis however, we discovered that there are some unfortunate missing pieces. 

When we have modeled `mtcars`, weight (`wt`) and horsepower (`hp`), and their interaction, have been most informative for predicting `mpg`. It would have been interesting to look at the evolution of the `mtcars` coefficients over time, but these variables are not unfortunately not available. In addition, it is hard to get a sense of fleet mileage without the annual unit-volume of each new car model. Because of this, it is impossible to know the evolution of more fuel efficient electric vehicles relative to more fuel-hungry model sales. 

It is difficult to understand why these variables are not included when that information must be available to the EPA, and it clearly says on page 6 of [Fuel Economy Guide 2020](https://www.fueleconomy.gov/feg/pdfs/guides/FEG2020.pdf) that an extra 100 lbs decreases fuel economy by 1%. While the data set is still of interest to practice for data cleaning, it doesn't look likely that we will be able replicate `mtcars` over time!


# Loading Data with fread

We tried to download both the origin zipped data directly from the EPA website (see link below), and the .csv from the Tidy Tuesday website, but were unsuccessful in both cases using Python and R versions of `fread`. We were able to download the Tidy Tuesday .csv link with `data.table`, but not with the `datatable` `fread`, and the error message didn't give us enough information to figure it out. The documentation for `data.table` fread is among the best of any function we know of, while there is not much documentation for `datatable`'s version yet. In the end, we downloaded the file from the EPA's website and uploaded from our local drive.


```{python 'load-big-mt'}
# Load vehicles
#https://www.fueleconomy.gov/feg/ws/index.shtml#fuelType1
#https://www.fueleconomy.gov/feg/epadata/vehicles.csv.zip
#https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-15/big_epa_cars.csv
big_mt = fread("~/Desktop/David/Projects/general_working/mt_cars/vehicles.csv")

# Dimensions
big_mt.shape

```

The list of all 83 variables below, and we can see that there are several pertaining to fuel efficiency, emissions, fuel type, range, volume and some of the same attributes that we all know from `mtcars` (ie: cylinders, displacement, make, model and transmission). As mentioned, gross horsepower and weight are missing, but carburetors, acceleration and engine shape are also absent. We have all classes of vehicles sold, so get vehicle class information (`VClass`) not available in `mtcars` which is only cars. We will discuss further down, changes to the weight cutoffs on some of the categories over time make `VClass` of questionable use.


```{python 'names', echo=TRUE}
# Extract names as list for further processing in next chunk
names = [name for name in big_mt.names]

# Set up pprint params and print
pp = pprint.PrettyPrinter(width=80, compact = True)
pp.pprint(names)
```


# Set-up Thoughts from R Perspective

There were a couple of things about the set-up for `datatable`, which weren't apparent coming over from `data.table` as an R user. The first was to use `from dt import *` at the outset to avoid having to reference the package short name every time within the frame. The second was to use `export_names()` in order to skip having to use the `f` operator or quotation marks to reference variables. In order to do this, we had to create a dictionary of names using the `names` list from above, and each of their `f` expressions extracted with `export_names` in a second list. We then used update from the local environment to assign all of the dictionary values to their keys as variables. From then on, we can refer to those variable without quotation marks or the `f` operator (although any new variables created would still need `f` or quotation marks). We weren't sure why this is not the default behavior, but it is easily worked around. These two steps brought the feel of `datatable` a lot closer to the usual R `data.table` (ie: without the package and expression short codes).


```{python 'export-all-names', include=FALSE}
# Export names to list to add to dictionary
expr = [exp for exp in big_mt.export_names()]

# Assign all exported name expressions to variable names
names_dict = {}
names_dict = { names[i]: expr[i] for i in range(len(names)) } 
locals().update(names_dict)

```


# Basic Filter and Select

A few lines of some key variables are shown in the code below, and it is clear that they need significant cleaning to be of use. One difference with R `data.table` can be seen below with filtering. Using our `year_filter` in `i` (the first slot), the 1204 2019 models are shown below. Unlike R `data.table`, we refer to `year` outside of the frame in an expression, and then call it within `i` of the frame. The columns can be selected within `()` or `[]` in `j` (the second slot) as shown below, and new columns can be created within `{}`.


```{python 'first-look', echo=TRUE}
# Key variables for year 2019
year_filter = (year == 2020)
print(big_mt[year_filter, (year, make, model, trany, evMotor, VClass)])

```


We usually like to make a quick check if there are any duplicated rows across the whole our dataFrame, but there isn't a duplicated() function yet in `datatable`. According to [How to find unique values for a field in Pydatatable Data Frame](https://stackoverflow.com/questions/61578175/how-to-find-unique-values-for-a-field-in-pydatatable-data-frame), the `unique()` function also doesn't apply to groups yet. In order to work around this, identifying variables would have to be grouped, counted and filtered for equal to 1, but we weren't sure yet exactly which variables to group on. We decided to pipe over to `pandas` to verify with a simple line of code that there were no duplicates, but hope this function will be added in the future.

# Aggregate New Variable and Sort

We can see that below that 'eng_dscr' is unfortunately blank 38% of the time, and high cardinality for the rest of the levels. A small percentage are marked "GUZZLER" and "FLEX FUELS". in a few cases, potentially helpful information about engine like V-6 or V-8 are included with very low frequency, but not consistently enough to make sense try to extract. Another potentially informative variable, `trans_dscr` is similarly blank more than 60% of the time. It seems unlikely that we could clean these up to make it useful in an analysis, so will probably have to drop them.


```{python 'eng_dscr', echo=TRUE}
print(big_mt[:, {'percent' : int32(count() * 100/big_mt.nrows) }, by(eng_dscr)]\
            [:,:, sort(-f.percent)])
```


# Separating and Assign New Variables

As shown above, `trany` has both the transmission-type and gear-speed variables within it, so we extracted the variable from big_mt with `to_list()`, drilled down one level, and used regex to extract the transmission and gear information needed out into `trans` and `gear`. Notice that we needed to convert the lists back into columns with dt.Frame before assigning as new variables in big_mt.

In the third line of code, we felt like we were using an R `data.table`. The `{}` is used group by `trans` and `gear`, and then to create the new `percent` variable in-line, without affecting the other variables in big_mt. We tried to round the decimals in percent, but couldn't figure it out so far. Our understanding is that there is no `round()` method yet for `datatable`, so we multiplied by 100 and converted to integer. We again called `export_names()`, to be consistent in using non-standard evaluation with the two new variables.


```{python 'split-trany', echo=TRUE}
big_mt['trans'] = dt.Frame([re.sub('[\s\(].*$','', s) for s in big_mt[:, 'trany'].to_list()[0]])
big_mt['gear'] = dt.Frame([re.sub('A\w+\s|M\w+\s','', s) for s in big_mt[:, 'trany'].to_list()[0]])
gear, trans= big_mt[:, ('gear', 'trans')].export_names()

# Summarize percent of instances by transmission and speed
print(big_mt[:, { 'percent' : int32(count() * 100 /big_mt.nrows) }, by(trans, gear)]\
            [0:13, : , sort(-f.percent)])

```

# Set Key and Join

We wanted to create a Boolean variable to denote if a vehicle had an electric motor or not. We again used `{}` to create the variable in the frame, but don't think it is possible to update by reference so still had to assign to `is_ev`. In the table below, we show the number of electric vehicles rising from 3 in 1998 to 149 this year. Unfortunately, 


```{python 'flag-ev', echo=TRUE}
# Create 'is_ev' within the frame
big_mt['is_ev'] = big_mt[:, { 'is_ev' : evMotor != '' }]
is_ev = big_mt[:, 'is_ev'].export_names()
ann_models = big_mt[:, {'all_models' : count()}, by(year)]
ev_models = big_mt[:, {'ev_models' : count() }, by('year', 'is_ev')]\
                  [(f.is_ev == 1), ('year', 'ev_models')]
ev_models.key = "year"
print(ann_models[:, :, join(ev_models)]\
                [:, { 'all_models' : f.all_models, 
                      'ev_models' : f.ev_models, 
                      'percent' : int32(f.ev_models * 100 / f.all_models) }, 
                      by(year)]\
                [(year > 1996), :])

```

# Using Regular Expressions in Row Operations

Next, we hoped to extract wheel-drive (2WD, AWD, 4WD, etc) and engine type (ie: V4, V6, etc) from `model`. The `re_match()` function is helpful in filtering rows in `i`. As shown below, we found almost 17k matches for wheel drive, but only 718 for the engine size. Given that we have over 42k rows, we will extract the wheels and give up on the engine data. It still may not be enough data for `wheels` to be a helpful variable.


```{python 'regex-filter-example', echo=TRUE}
# Regex match with re_match()
print('%d of rows with wheels info.' % (big_mt[model.re_match('.*(.WD).*'), model].nrows))
print('%d of rows with engine info.' % (big_mt[model.re_match('.*(V|v)(\s|\-)?\d+.*'), model].nrows))

```


We used regex to extract whether the model was 2WD, 4WD, etc as `wheels` from `model`, but most of the time, it was the same information as we already had in `drive`. It is possible that our weakness in Python is at play, but this would have been a lot simpler in R, because we wouldn't have iterated over every row in order to extract part of the row with regex. We found that there were some cases where the 2WD and 4WD were recorded as 2wd and 4wd. The `replace()` function was an efficient solution to this problem, replacing matches of 'wd' with 'WD' over the entire frame.


```{python 'wheel-engine', echo=TRUE}
# Extract 'wheels' and 'engine' from 'model'
reg = re.compile(r'(.*)(.WD|4x4)(.*)', re.IGNORECASE)
big_mt[:, 'wheels'] = dt.Frame([reg.match(s).group(2) if reg.search(s) else '' for s in big_mt[:, model].to_list()[0]])
wheels = big_mt[:, 'wheels'].export_names()

# Fix problem notations
big_mt.replace("\dwd", "\dWD")

# Summarize total count for all years
cols = ['make', 'model', 'cylinders', 'wheels', 'drive']
print(big_mt[(f.wheels != ''), cols]\
            [:, count(), by(f.wheels, cylinders, drive)]\
            [0:14:, :, sort(-f.count)])

```


# Reshaping

There was no such thing as an 4-wheel drive SUVs back in the 80's, and we remember the big 8-cylinder Oldsmobiles and Cadillacs, so were curious how these models evolved over time. `datatable` doesn't yet have dcast() or melt(), so we had to pipe these out `to_pandas()` and then use `pivot_table()`. Its likely that a lot of the the many models where wheel-drive was unspecified were 2WD, which is still the majority of models. We would have liked to show these as whole numbers, and there is a workaround in `datatable` to convert to integer, but once we pivoted in `pandas`, it reverted to float. We can see the first AWD models starting in the late 80s, and the number of 8-cylinder cars fall by half. There are are a lot fewer annual new car models now than in the 80s, but were surprised how many fewer 4-cylinders.


```{python 'models-over-time', echo=TRUE}
# Summarize by year again having to move to pandas to pivot
print(big_mt[:, count(), by(f.wheels, year)].to_pandas().pivot_table(index='wheels', columns='year', values='count'))

print(big_mt[:, count(), by(cylinders, year)].to_pandas().pivot_table(index='cylinders', columns='year', values='count'))

```



```{python 'cleaner-function', include=FALSE}
# Control flow statement used to collapse VClass levels in clean-vclass chunk below
def collapse_vclass(type):
  if type in ['Compact Cars', 'Two Seaters', 'Subcompact Cars', 'Minicompact Cars', 'Small Station Wagons']:
      type = 'Small Car'
  elif type in ['Midsize Cars', 'Midsize Station Wagons']:
      type = 'Midsize Car'
  elif type in ['Midsize-Large Station Wagons', 'Large Cars']:
      type = 'Large Car'
  elif type in ['Special Purpose Vehicle', 'Special Purpose Vehicles']:
      type = 'Special Purpose Vehicle'
  elif type in ['Vans Passenger', 'Vans, Passenger Type', 'Vans, Cargo Type', 'Vans']:
      type = 'Vans'
  elif type in ['Sport Utility Vehicle', 'Standard Sport Utility Vehicle']:
      type = 'Sport Utility Vehicle'
  elif type in ['Small Pickup Trucks', 'Small Sport Utility Vehicle']:
      type = 'Small Pickup and SUV'
  return type
  
```


# Combining Levels of Variables with High Cardinality

With 35 distinct levels often referring to similar vehicles, `VClass` also needed to be cleaned up. Even in R `data.table`, we have been keenly awaiting the implemention of `fcase`, which is expected to replicate the `dplyr` `case_when()` function for nested control-flow statements. We made a separate 16-line function to lump factor levels (not shown). In the first line below, we created the `vclasses` list to drill down on the `VClass` tuple elements as strings. In the second line, we had to iterate over the resulting strings from the 0-index of the tuple to extract wheel-drive from a list-comprehension. We printed out the result of our much smaller list of lumped factors, but there are still problems with the result. The EPA changed the cutoff for a "Small Pickup Truck" from 4,500 to 6,000 lbs in 2008, and also used a higher cut-off for "small" SUV's starting in 2011. This will make it pretty hard to us VClass as a consistent variable for modeling, at least for Pickups and SUVs. As noted earlier, if we had the a weight field, we could have easily worked around this.


```{python}
# Clean up vehicle type from VClass
vclasses = [tup[0] for tup in big_mt[:, 'VClass'].to_tuples()]
big_mt['VClass'] = dt.Frame([re.sub('\s\dWD$|\/\dwd$|\s\-\s\dWD$', '', x) if re.search(r'WD$|wd$', x) is not None else x for x in vclasses])
big_mt['VClass'] = dt.Frame([collapse_vclass(line[0]) for line in big_mt[:, 'VClass'].to_tuples()])

# Show final VClass types
print(dt.unique(big_mt["VClass"]))

```


# Selecting Multiple Columns with Regex

In the chunk (below), we show how to select columns from the big_mt names tuple by creating the `measures` selector using regex matches for the key identifier columns and for integer mileage columns matching '08'. This seemed complicated and we couldn't do it in line within the frame as we would have with `data.table` .SD = patterns(). We also wanted to reorder to move the identifier columns (`year`, `make` and `model`) to the left side of the table, but couldn't find a equivalent `setcolorder` function. There is documentation about multi-column selection, but we couldn't figure out an efficient way to make it work. We show the frame with the `year_filter` which we set up earlier. 


```{python 'filter-examples', echo = TRUE}
# Regex search for variable selection
measures = [x for x in big_mt.names if re.search(r'make|model|year|08$', x)]

# Print remaining cols with measures filter
print(big_mt[year_filter,  measures])

```

# Selecting Columns and Exploring Summary Data

We looked for a Python version of `skimr`, but it doesn't seem like there is an similar library (as is often the case). We tried out `pandas profiling`, but that had a lot of dependencies and seemed like overkill for our purposes, so decided to use `skim_tee` on the table in a separate R chunk (below). It was necessary to convert to `pandas` in the Python chunk (above), because we couldn't figure out how to translate a `datatable` back to a data.frame via `reticulate` in the R chunk. 

When we did convert, we discovered there were some problems mapping NA's which we will show below. We suspect it isn't possible to pass a `datatable` to `data.table`, and this might be the first functionality we would vote to add. There is a sizable community of `data.table` users who are used to the syntax, and as we are, might be looking to port into Python (rather than learn `pandas` directly). As `reticulate` develops, opening this door seems to make so much sense. 
Below, we again run `export_names()` in order to also prepare the newly generated variables for non-standard evaluation within the frame, and then filtered for the 21 columns we wanted to keep.


```{python 'select-skimr-cols', echo=TRUE}
# List of cols to keep
cols = ['make', 
        'model', 
        'year', 
        'city08', 
        'highway08', 
        'comb08', 
        'VClass', 
        'drive',
        'fuelType1', 
        'hlv', 
        'hpv', 
        'cylinders', 
        'displ',
        'trans', 
        'gear',
        'wheels',
        'is_ev',
        'evMotor', 
        'guzzler',
        'tCharger',
        'sCharger']

# Select cols and create pandas version
big_mt_pandas = big_mt[:, cols].to_pandas()
```

```{r 'skimr', echo=TRUE, message=FALSE, warning=FALSE}
# Skimr
skim_tee(py$big_mt_pandas)

```

In the result above, we see a lot of challenges if we had hoped to have appropriate data to build a model to predict mpg over time. Many variables, such as `evMotor`, `tCharger`, `sCharger` and `guzzler`, are only available in a small number of rows. When we set out on this series, we hoped we would be able to experiment with modeling gas mileage for every year just like `mtcars`, but that seems unlikely based on the available variables.


# Conclusion

It took us a couple of months to get up and running with R `data.table`, and even with daily usage, we are still learning its nuance a year later. We think the up-front investment in learning the syntax, which can be a little confusing  at first, has been worth it. It is also less well documented than `dplyr` or `pandas`. We learned so much about `data.table` from a few blog posts such as [Advanced tips and tricks with data.table](http://brooksandrew.github.io/simpleblog/articles/advanced-data-table/) and [A data.table and dplyr tour](https://atrebas.github.io/post/2019-03-03-datatable-dplyr/). The goal of this post is to help to similarly fill the gap for `datatable`. 

Python `datatable` is promising, and we are grateful for it as familiar territory as we learn Python. We can't tell how much of our difficulty has been because the package is not quite mature compared to the mature `data.table` or our just inexperience with Python. The need to manually set variables for non-standard evaluation, to revert to pandas to accomplish certain tasks (ie: reshaping) or the challenges extracting and filtering data from nested columns. It was still not easy to navigate the documentation and there were areas where the documentation was not Also, it would be appreciated to seamlessly translate between a `datatable` and `data.table`. In the next post, we will continue to use Big MT Cars data to try out `plotnine`, the Python version of `ggplot`.

